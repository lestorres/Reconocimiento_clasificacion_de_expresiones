# Integraci√≥n


```mermaid
flowchart TB

    subgraph Espectador
        Z[üòÉ Reacci√≥n del Espectador]
    end

    subgraph Camara USB
        A[üì∑ Entrada de video o Captura de im√°genes]
    end

    subgraph Raspberry Pi 5
        B[üîß Preprocesamiento con OpenCV]
        C[üß† Procesamiento con TFLite]
        D[üß™ Clasificaci√≥n con Modelo Edge IA]
        E[üíæ Almacenamiento local de resultados]
        F[üì§ Env√≠o de paquetes v√≠a WiFi/Ethernet]
    end

    subgraph Servidor Central
        G[üìä Visualizaci√≥n]
        H[üñ•Ô∏è Interfaz Gr√°fica para Operador]
        I[üïπÔ∏è Control de Ciclo o Ajustes]
    end

    Z --> A
    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G
    G --> H
    H --> I
    I --> B

```


## üß© Descripci√≥n del proceso de integraci√≥n hardware/software
La soluci√≥n implementada combina de forma coordinada componentes de hardware y software para lograr un sistema funcional de detecci√≥n y visualizaci√≥n de emociones. A continuaci√≥n se detalla c√≥mo se integran y complementan estos componentes en cada etapa del proceso:

- üòÉ Reacci√≥n del Espectador: Es la reacci√≥n o la expresi√≥n de la emoci√≥n por parte del espectador

- üü¶ C√°mara USB (hardware): Es el punto de entrada del sistema. Captura im√°genes en tiempo real del espectador o usuario cuya expresi√≥n emocional ser√° analizada.

- üü© Raspberry Pi 5 (hardware + software): Act√∫a como nodo de procesamiento en el borde. Recibe la imagen desde la c√°mara y ejecuta varios procesos:

  - OpenCV (software): Realiza el preprocesamiento de la imagen (detecci√≥n de rostro, recorte, escalado y normalizaci√≥n).

  - TensorFlow Lite (software): Ejecuta el modelo de aprendizaje autom√°tico entrenado para clasificar emociones en tiempo real.

  - Red de comunicaci√≥n (hardware/software): Se utiliza WiFi o Ethernet para transferir los resultados inferidos (emociones y timestamps) al servidor central.

- üü• Servidor Central (hardware + software): Recibe los datos procesados desde la Raspberry Pi y permite la interacci√≥n con el operador:

  - Interfaz Gr√°fica (software): Presenta visualmente las emociones detectadas y permite al operador ajustar par√°metros del sistema (por ejemplo, encender/apagar el ciclo de inferencia o cambiar umbrales de confianza).

  - Control remoto del ciclo de procesamiento (software): El operador puede modificar el comportamiento del sistema en tiempo real, enviando instrucciones de vuelta a la Raspberry Pi.

Este dise√±o modular e integrado permite una interacci√≥n fluida entre hardware y software: la Raspberry Pi se encarga de la inferencia local, optimizando la latencia y reduciendo la carga sobre la red, mientras que el servidor central act√∫a como centro de control y visualizaci√≥n, facilitando ajustes remotos y monitoreo continuo.
